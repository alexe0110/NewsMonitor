import io
import json
import logging
import os
from datetime import datetime

import clickhouse_connect
from airflow.models import BaseOperator
from minio import Minio

logger = logging.getLogger(__name__)


class TextPreprocessingOperator(BaseOperator):
    """
    –û–ø–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–µ—Ä–µ–¥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π.

    –ß–∏—Ç–∞–µ—Ç JSON —Ñ–∞–π–ª—ã –∏–∑ raw-news bucket, –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç title + description,
    –æ–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ processed-news bucket.

    Args:
        source_bucket: Bucket –¥–ª—è —á—Ç–µ–Ω–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        target_bucket: Bucket –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        source_files: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.
        max_text_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (default: 2000).
    """

    template_fields = ('source_files',)

    def __init__(
        self,
        *,
        source_bucket: str = 'raw-news',
        target_bucket: str = 'processed-news',
        source_files: list[str],
        max_text_length: int = 2000,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self.source_bucket = source_bucket
        self.target_bucket = target_bucket
        self.source_files = source_files
        self.max_text_length = max_text_length

    def _get_minio_client(self) -> Minio:
        """–°–æ–∑–¥–∞–Ω–∏–µ MinIO –∫–ª–∏–µ–Ω—Ç–∞ –∏–∑ environment variables."""
        return Minio(
            endpoint=os.getenv('MINIO_ENDPOINT', 'minio:9000'),
            access_key=os.getenv('MINIO_ACCESS_KEY', 'minioadmin'),
            secret_key=os.getenv('MINIO_SECRET_KEY', 'minioadmin'),
            secure=False,
        )

    def _get_clickhouse_client(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ ClickHouse –∫–ª–∏–µ–Ω—Ç–∞."""
        return clickhouse_connect.get_client(
            host=os.getenv('CLICKHOUSE_HOST', 'clickhouse'),
            username=os.getenv('CLICKHOUSE_USER', 'default'),
            password=os.getenv('CLICKHOUSE_PASSWORD', 'clickhouse'),
            database=os.getenv('CLICKHOUSE_DB', 'news_analytics'),
        )

    def _read_json_from_minio(self, client: Minio, bucket: str, filename: str) -> list:
        """–ß—Ç–µ–Ω–∏–µ JSON —Ñ–∞–π–ª–∞ –∏–∑ MinIO."""
        response = client.get_object(bucket, filename)
        data = json.loads(response.read().decode('utf-8'))
        response.close()
        response.release_conn()
        return data

    def _save_json_to_minio(self, client: Minio, bucket: str, filename: str, data: list) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –¥–∞–Ω–Ω—ã—Ö –≤ MinIO."""
        json_bytes = json.dumps(data, indent=2, ensure_ascii=False).encode('utf-8')
        client.put_object(
            bucket_name=bucket,
            object_name=filename,
            data=io.BytesIO(json_bytes),
            length=len(json_bytes),
            content_type='application/json',
        )

    def _log_processing(
        self,
        ch_client,
        raw_files: list[str],
        processed_file: str,
        items_count: int,
    ) -> None:
        records = [
            [
                f'{self.source_bucket}/{filename}',
                f'{self.target_bucket}/{processed_file}',
                'success',
                items_count,
            ]
            for filename in raw_files
        ]
        ch_client.insert(
            'processing_log',
            records,
            column_names=[
                'raw_file_path',
                'processed_file_path',
                'status',
                'items_count',
            ],
        )

    def _process_item(self, item: dict) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–æ–≤–æ—Å—Ç–∏."""
        source = item.get('source', 'unknown')

        if source == 'hackernews':
            item_id = f'hn_{item.get("id")}'
            text = item.get('title', '')
            published_at = datetime.fromtimestamp(item.get('time', 0)).isoformat() if item.get('time') else None
        else:  # devto
            item_id = f'devto_{item.get("id")}'
            title = item.get('title', '')
            description = item.get('description', '')
            text = f'{title}. {description}' if description else title
            published_at = item.get('published_at')

        # –û–±—Ä–µ–∑–∞–µ–º —Ç–µ–∫—Å—Ç –¥–æ max_text_length
        if len(text) > self.max_text_length:
            text = text[: self.max_text_length - 3] + '...'

        return {
            'id': item_id,
            'text': text,
            'source': source,
            'url': item.get('url'),
            'original_title': item.get('title'),
            'published_at': published_at,
        }

    def execute(self, context) -> int:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞."""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
        if not self.source_files:
            logger.warning('‚ö†Ô∏è –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, –ø—Ä–æ–ø—É—Å–∫')
            return 0

        minio_client = self._get_minio_client()
        ch_client = self._get_clickhouse_client()
        processed_items: list[dict] = []

        for filename in self.source_files:
            logger.info('üìñ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: %s/%s', self.source_bucket, filename)

            try:
                raw_items = self._read_json_from_minio(minio_client, self.source_bucket, filename)
                logger.info('üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ %d —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ %s', len(raw_items), filename)

                for item in raw_items:
                    processed = self._process_item(item)
                    processed_items.append(processed)

            except Exception as e:
                logger.error('‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ %s: %s', filename, e)
                raise

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ MinIO
        output_filename = f'{datetime.now().strftime("%Y-%m-%d_%H%M")}_processed.json'
        self._save_json_to_minio(minio_client, self.target_bucket, output_filename, processed_items)
        logger.info(
            '‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ %d —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ %s/%s',
            len(processed_items),
            self.target_bucket,
            output_filename,
        )

        self._log_processing(ch_client, self.source_files, output_filename, len(processed_items))
        logger.info('üìù –ó–∞–ø–∏—Å–∞–Ω–æ –≤ processing_log')

        # Push –≤ XCom
        ti = context.get('task_instance')
        if ti:
            ti.xcom_push(key='processed_file', value=output_filename)

        return len(processed_items)
